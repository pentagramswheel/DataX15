{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import data cleaning libraries\n",
    "import bs4 as bs\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for topic detection\n",
    "\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install vaderSentiment\n",
    "\n",
    "# !pip install http://download.pytorch.org/whl/cu90/torch-0.4.1-cp36-cp36m-win_amd64.whl \n",
    "# !pip install torchvision\n",
    "\n",
    "# !conda install pytorch torchvision cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "available_torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'insurance', \n",
    "    'safety', \n",
    "    'balance', \n",
    "    'retirement', \n",
    "    'culture', \n",
    "    'racism', \n",
    "    'sexism', \n",
    "    'ageism', \n",
    "    'benefits', \n",
    "    'opportunities', \n",
    "    'privacy', \n",
    "    'resources']\n",
    "\n",
    "print(len(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass_door_review_cleaner(reviews):\n",
    "    \"\"\"\n",
    "    Cleans a review retrieved from the Glass Door scraper.\n",
    "    \n",
    "    Args:\n",
    "        reviews::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "            \n",
    "    Return:\n",
    "       clean_reviews::[pd.DataFrame]\n",
    "            The cleaned version of the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    # drop any columns, if needed\n",
    "    clean_reviews = reviews.drop([], axis = 1)\n",
    "    \n",
    "    # remove newline characters\n",
    "    clean_reviews['pros'] = clean_reviews['pros'].str.replace('\\n', '', regex = True)\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace('\\n', '', regex = True)\n",
    "    \n",
    "    # remove carriage returns\n",
    "    clean_reviews['pros'] = clean_reviews['pros'].str.replace('\\r', '', regex = True)\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace('\\r', '', regex = True)\n",
    "\n",
    "    # remove bad strings caught by the web scraper\n",
    "    badString1 = \"Verify your email to continue reading or Resend email\"\n",
    "    badString2 = \"Be the first to find this review helpfulHelpfulShareRepor\"\n",
    "\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace(badString1, '', regex = True)\n",
    "    clean_reviews['cons'] = clean_reviews['cons'].str.replace(badString2, '', regex = True)\n",
    "\n",
    "    # compile pros and cons together into a column\n",
    "    clean_reviews['text'] = \"{ Pros. \" + clean_reviews['pros'] + \" } { Cons. \" + clean_reviews['cons'] + \" }\"\n",
    "\n",
    "    # remove empty reviews\n",
    "    clean_reviews = clean_reviews.dropna(subset = ['text'])\n",
    "    clean_reviews = clean_reviews.reset_index(drop = True)\n",
    "    \n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_review_cleaner(reviews, lemmatize = True, stem = False):\n",
    "    \"\"\"\n",
    "    Clean and preprocess a review.\n",
    "\n",
    "    Args:\n",
    "        reviews::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "        lemmatize::[boolean]\n",
    "            A flag for feature lemmatization.\n",
    "        stem::[boolean]\n",
    "            A flag for feature stemming.\n",
    "            \n",
    "    Return:\n",
    "        cleaned_reviews::[pd.DataFrame]\n",
    "            The cleaned version of the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    #1. Remove HTML tags\n",
    "    cleaned_reviews=[]\n",
    "    for i,review in enumerate(reviews['text']):\n",
    "    # print progress\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(\"Done with %d reviews\" %(i+1))\n",
    "        review = bs.BeautifulSoup(review).text\n",
    "\n",
    "        #2. Use regex to find emoticons\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "\n",
    "        #3. Remove punctuation\n",
    "        review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "\n",
    "        #4. Tokenize into words (all lower case)\n",
    "        review = review.lower().split()\n",
    "\n",
    "        #5. Remove stopwords\n",
    "        eng_stopwords = set(stopwords.words(\"english\"))\n",
    "            \n",
    "        clean_review = []\n",
    "        for word in review:\n",
    "            if word not in eng_stopwords:\n",
    "                if lemmatize is True:\n",
    "                    word = wnl.lemmatize(word)\n",
    "                elif stem is True:\n",
    "                    if word == 'oed':\n",
    "                        continue\n",
    "                    word = ps.stem(word)\n",
    "                clean_review.append(word)\n",
    "\n",
    "        #6. Join the review to one sentence\n",
    "        review_processed = ' '.join(clean_review + emoticons)\n",
    "        cleaned_reviews.append(review_processed)\n",
    "    \n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def round_two_digit_string(x):\n",
    "    \"\"\"\n",
    "    Rounds a float to two decimal places.\n",
    "    \n",
    "    Args:\n",
    "        x::[float]\n",
    "            The float number to round.\n",
    "            \n",
    "    Return:\n",
    "            The rounded float.\n",
    "    \"\"\"\n",
    "    return str(round(x, 2))\n",
    "\n",
    "def retrieve_sentiment_analysis(df, column):\n",
    "    \"\"\" Performs a sentiment analysis on the given data.\n",
    "    \n",
    "    Args:\n",
    "        df::[pd.DataFrame]\n",
    "            The table of given reviews and their statistics.\n",
    "            \n",
    "    Return:\n",
    "        sentiment_df::[pd.DataFrame]\n",
    "            The reviews with their sentiment analysis data.\n",
    "    \"\"\"\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    data = {\n",
    "        \"text\": [],\n",
    "        \"negative\": [],\n",
    "        \"neutral\": [],\n",
    "        \"positive\": [],\n",
    "        \"compound\": []\n",
    "    }\n",
    "\n",
    "    for sentence in df[column]:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "\n",
    "        data[\"text\"].append(sentence)\n",
    "        data[\"negative\"].append(round_two_digit_string(vs[\"neg\"]))\n",
    "        data[\"neutral\"].append(round_two_digit_string(vs[\"neu\"]))\n",
    "        data[\"positive\"].append(round_two_digit_string(vs[\"pos\"]))\n",
    "        data[\"compound\"].append(round_two_digit_string(vs[\"compound\"]))\n",
    "        \n",
    "    sentiment_df = pd.DataFrame(data)\n",
    "    \n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" A Dataset class for PyTorch data loading. \"\"\"\n",
    "    \n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Initial_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>insurance</th>\n",
       "      <th>safety</th>\n",
       "      <th>balance</th>\n",
       "      <th>retirement</th>\n",
       "      <th>culture</th>\n",
       "      <th>racism</th>\n",
       "      <th>sexism</th>\n",
       "      <th>ageism</th>\n",
       "      <th>benefits</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>privacy</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5145.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>Work life balance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5134.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>Many opportunities off program to explore diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5132.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>Flexible Leadership is strong Challenging Lear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5126.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>Collaborative culture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5123.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>Culture Work ethics technology quality experts.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Initial_ID                                               text  \\\n",
       "0  5145.0       743.0                                  Work life balance   \n",
       "1  5134.0       732.0  Many opportunities off program to explore diff...   \n",
       "2  5132.0       730.0  Flexible Leadership is strong Challenging Lear...   \n",
       "3  5126.0       724.0                              Collaborative culture   \n",
       "4  5123.0       721.0   Culture Work ethics technology quality experts.    \n",
       "\n",
       "   insurance  safety  balance  retirement  culture  racism  sexism  ageism  \\\n",
       "0          0       0        1           0        0       0       0       0   \n",
       "1          0       0        0           0        0       0       0       0   \n",
       "2          0       0        1           0        0       0       0       0   \n",
       "3          0       0        0           0        1       0       0       0   \n",
       "4          0       0        0           0        1       0       0       0   \n",
       "\n",
       "   benefits  opportunities  privacy  resources  \n",
       "0         0              0        0          0  \n",
       "1         0              1        0          0  \n",
       "2         0              1        0          0  \n",
       "3         0              0        0          0  \n",
       "4         0              0        0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1 - OPEN CLASSIFIER DATASET [currently set to classify pros]\n",
    "# train = pd.read_csv(\"train_old.csv\", header = 0, sep = \",\")\n",
    "train = pd.read_csv(\"train.csv\", header = 0, sep = \",\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>insurance</th>\n",
       "      <th>safety</th>\n",
       "      <th>balance</th>\n",
       "      <th>retirement</th>\n",
       "      <th>culture</th>\n",
       "      <th>racism</th>\n",
       "      <th>sexism</th>\n",
       "      <th>ageism</th>\n",
       "      <th>benefits</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>privacy</th>\n",
       "      <th>resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Work life balance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many opportunities off program to explore diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flexible Leadership is strong Challenging Lear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collaborative culture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture Work ethics technology quality experts.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  insurance  safety  \\\n",
       "0                                  Work life balance          0       0   \n",
       "1  Many opportunities off program to explore diff...          0       0   \n",
       "2  Flexible Leadership is strong Challenging Lear...          0       0   \n",
       "3                              Collaborative culture          0       0   \n",
       "4   Culture Work ethics technology quality experts.           0       0   \n",
       "\n",
       "   balance  retirement  culture  racism  sexism  ageism  benefits  \\\n",
       "0        1           0        0       0       0       0         0   \n",
       "1        0           0        0       0       0       0         0   \n",
       "2        1           0        0       0       0       0         0   \n",
       "3        0           0        1       0       0       0         0   \n",
       "4        0           0        1       0       0       0         0   \n",
       "\n",
       "   opportunities  privacy  resources  \n",
       "0              0        0          0  \n",
       "1              1        0          0  \n",
       "2              1        0          0  \n",
       "3              0        0          0  \n",
       "4              0        0          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop useless data\n",
    "# train = train.drop([\"Unnamed: 0\", \"ID\", \"Initial_ID\", \"S\"], axis = 1)\n",
    "train = train.drop([\"ID\", \"Initial_ID\"], axis = 1)\n",
    "train = train.dropna()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1907\n",
      "1      97\n",
      "Name: insurance, dtype: int64\n",
      "\n",
      "0    1919\n",
      "1      85\n",
      "Name: safety, dtype: int64\n",
      "\n",
      "0    1646\n",
      "1     358\n",
      "Name: balance, dtype: int64\n",
      "\n",
      "0    1965\n",
      "1      39\n",
      "Name: retirement, dtype: int64\n",
      "\n",
      "0    1625\n",
      "1     379\n",
      "Name: culture, dtype: int64\n",
      "\n",
      "0    1984\n",
      "1      20\n",
      "Name: racism, dtype: int64\n",
      "\n",
      "0    1989\n",
      "1      15\n",
      "Name: sexism, dtype: int64\n",
      "\n",
      "0    1992\n",
      "1      12\n",
      "Name: ageism, dtype: int64\n",
      "\n",
      "0    1380\n",
      "1     624\n",
      "Name: benefits, dtype: int64\n",
      "\n",
      "0    1643\n",
      "1     361\n",
      "Name: opportunities, dtype: int64\n",
      "\n",
      "0    2000\n",
      "1       4\n",
      "Name: privacy, dtype: int64\n",
      "\n",
      "0    1909\n",
      "1      95\n",
      "Name: resources, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# review the dataset\n",
    "for metric in metrics:\n",
    "    uvc = train[metric].value_counts(sort = True, ascending = False)\n",
    "    print(f'{uvc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How big would you like your batch size to be?: 40\n",
      "Batch size will then be 60 and the testing size will be 20.0%.\n",
      "\n",
      "Metric List: ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
      "Which of the 12 metrics would you like to focus on currently?: resources\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = int(input(\"How big would you like your batch size to be?: \"))\n",
    "EVAL_BATCH_SIZE = TRAIN_BATCH_SIZE + 20\n",
    "TEST_PORTION = 0.2\n",
    "print(f'Batch size will then be {EVAL_BATCH_SIZE} and the testing size will be {TEST_PORTION * 100}%.')\n",
    "\n",
    "print(f'\\nMetric List: {metrics}')\n",
    "CURRENT_METRIC = input(f'Which of the {len(metrics)} metrics would you like to focus on currently?: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1603, 2) (401, 2)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 - TOKENIZE INPUT AND CREATE TRAINING/TESTING SETS\n",
    "Xtrain_insurance, Xval_insurance = train_test_split(train[['text', 'insurance']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_safety, Xval_safety = train_test_split(train[['text', 'safety']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_balance, Xval_balance = train_test_split(train[['text', 'balance']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_retirement, Xval_retirement = train_test_split(train[['text', 'retirement']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_culture, Xval_culture = train_test_split(train[['text', 'culture']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_racism, Xval_racism = train_test_split(train[['text', 'racism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_sexism, Xval_sexism = train_test_split(train[['text', 'sexism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_ageism, Xval_ageism = train_test_split(train[['text', 'ageism']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_benefits, Xval_benefits = train_test_split(train[['text', 'benefits']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_opportunities, Xval_opportunities = train_test_split(train[['text', 'opportunities']], random_state = 0, test_size = TEST_PORTION) \n",
    "Xtrain_privacy, Xval_privacy = train_test_split(train[['text', 'privacy']], random_state = 0, test_size = TEST_PORTION)\n",
    "Xtrain_resources, Xval_resources = train_test_split(train[['text', 'resources']], random_state = 0, test_size = TEST_PORTION)\n",
    "\n",
    "Xtrains = {\n",
    "    'insurance': Xtrain_insurance,\n",
    "    'safety': Xtrain_safety,\n",
    "    'balance': Xtrain_balance,\n",
    "    'retirement': Xtrain_retirement,\n",
    "    'culture': Xtrain_culture,\n",
    "    'racism': Xtrain_racism,\n",
    "    'sexism': Xtrain_sexism,\n",
    "    'ageism': Xtrain_ageism,\n",
    "    'benefits': Xtrain_benefits,\n",
    "    'opportunities': Xtrain_opportunities,\n",
    "    'privacy': Xtrain_privacy,\n",
    "    'resources': Xtrain_resources\n",
    "}\n",
    "\n",
    "Xvals = {\n",
    "    'insurance': Xval_insurance,\n",
    "    'safety': Xval_safety,\n",
    "    'balance': Xval_balance,\n",
    "    'retirement': Xval_retirement,\n",
    "    'culture': Xval_culture,\n",
    "    'racism': Xval_racism,\n",
    "    'sexism': Xval_sexism,\n",
    "    'ageism': Xval_ageism,\n",
    "    'benefits': Xval_benefits,\n",
    "    'opportunities': Xval_opportunities,\n",
    "    'privacy': Xval_privacy,\n",
    "    'resources': Xval_resources\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BERT model, the text inputs must be converted to tokens with tokenizer\n",
    "# Here we use a distiled version of BERT base model (DistilBERT) for fast prototyping\n",
    "# https://huggingface.co/distilbert-base-cased \n",
    "# The tokenizer to use is the pretrained DistilBERT tokenizer\n",
    "# https://huggingface.co/transformers/model_doc/distilbert.html#transformers.DistilBertTokenizer\n",
    "# Feel free to try on different pretrained BERT model for your own applications but please remember to match the tokenizer with\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "# with the selected tokenizer, prepare the inputs and labels with correct datatype for each label\n",
    "tokenized_train_insurance = tokenizer(Xtrain_insurance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_insurance = tokenizer(Xval_insurance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_insurance = Xtrain_insurance['insurance'].tolist()\n",
    "val_labels_insurance = Xval_insurance['insurance'].tolist()\n",
    "\n",
    "tokenized_train_safety = tokenizer(Xtrain_safety['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_safety = tokenizer(Xval_safety['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_safety = Xtrain_safety['safety'].tolist()\n",
    "val_labels_safety = Xval_safety['safety'].tolist()\n",
    "\n",
    "tokenized_train_balance = tokenizer(Xtrain_balance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_balance = tokenizer(Xval_balance['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_balance = Xtrain_balance['balance'].tolist()\n",
    "val_labels_balance = Xval_balance['balance'].tolist()\n",
    "\n",
    "tokenized_train_retirement = tokenizer(Xtrain_retirement['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_retirement = tokenizer(Xval_retirement['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_retirement = Xtrain_retirement['retirement'].tolist()\n",
    "val_labels_retirement = Xval_retirement['retirement'].tolist()\n",
    "\n",
    "tokenized_train_culture = tokenizer(Xtrain_culture['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_culture = tokenizer(Xval_culture['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_culture = Xtrain_culture['culture'].tolist()\n",
    "val_labels_culture = Xval_culture['culture'].tolist()\n",
    "\n",
    "tokenized_train_racism = tokenizer(Xtrain_racism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_racism = tokenizer(Xval_racism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_racism = Xtrain_racism['racism'].tolist()\n",
    "val_labels_racism = Xval_racism['racism'].tolist()\n",
    "\n",
    "tokenized_train_sexism = tokenizer(Xtrain_sexism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "tokenized_val_sexism = tokenizer(Xval_sexism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_sexism = Xtrain_sexism['sexism'].tolist()\n",
    "val_labels_sexism = Xval_sexism['sexism'].tolist()\n",
    "\n",
    "tokenized_train_ageism = tokenizer(Xtrain_ageism['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_ageism = tokenizer(Xval_ageism['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_ageism = Xtrain_ageism['ageism'].tolist()\n",
    "val_labels_ageism = Xval_ageism['ageism'].tolist()\n",
    "\n",
    "tokenized_train_benefits = tokenizer(Xtrain_benefits['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_benefits = tokenizer(Xval_benefits['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_benefits = Xtrain_benefits['benefits'].tolist()\n",
    "val_labels_benefits = Xval_benefits['benefits'].tolist()\n",
    "\n",
    "tokenized_train_opportunities = tokenizer(Xtrain_opportunities['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_opportunities = tokenizer(Xval_opportunities['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_opportunities = Xtrain_opportunities['opportunities'].tolist()\n",
    "val_labels_opportunities = Xval_opportunities['opportunities'].tolist()\n",
    "\n",
    "tokenized_train_privacy = tokenizer(Xtrain_privacy['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_privacy = tokenizer(Xval_privacy['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_privacy = Xtrain_privacy['privacy'].tolist()\n",
    "val_labels_privacy = Xval_privacy['privacy'].tolist()\n",
    "\n",
    "tokenized_train_resources = tokenizer(Xtrain_resources['text'].tolist(), padding = \"max_length\", truncation = True) \n",
    "tokenized_val_resources = tokenizer(Xval_resources['text'].tolist(), padding = \"max_length\", truncation = True)\n",
    "train_labels_resources = Xtrain_resources['resources'].tolist()\n",
    "val_labels_resources = Xval_resources['resources'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the tokenized inputs and labels into PyTorch datasets\n",
    "train_dataset_insurance = MYDataset(tokenized_train_insurance, train_labels_insurance)\n",
    "val_dataset_insurance = MYDataset(tokenized_val_insurance, val_labels_insurance)\n",
    "train_loader_insurance = DataLoader(train_dataset_insurance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_insurance = DataLoader(val_dataset_insurance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_safety = MYDataset(tokenized_train_safety, train_labels_safety)\n",
    "val_dataset_safety = MYDataset(tokenized_val_safety, val_labels_safety)\n",
    "train_loader_safety = DataLoader(train_dataset_safety, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_safety = DataLoader(val_dataset_safety, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_balance = MYDataset(tokenized_train_balance, train_labels_balance)\n",
    "val_dataset_balance = MYDataset(tokenized_val_balance, val_labels_balance)\n",
    "train_loader_balance = DataLoader(train_dataset_balance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_balance = DataLoader(val_dataset_balance, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_retirement = MYDataset(tokenized_train_retirement, train_labels_retirement)\n",
    "val_dataset_retirement = MYDataset(tokenized_val_retirement, val_labels_retirement)\n",
    "train_loader_retirement = DataLoader(train_dataset_retirement, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_retirement = DataLoader(val_dataset_retirement, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_culture = MYDataset(tokenized_train_culture, train_labels_culture)\n",
    "val_dataset_culture = MYDataset(tokenized_val_culture, val_labels_culture)\n",
    "train_loader_culture = DataLoader(train_dataset_culture, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_culture = DataLoader(val_dataset_culture, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_racism = MYDataset(tokenized_train_racism, train_labels_racism)\n",
    "val_dataset_racism = MYDataset(tokenized_val_racism, val_labels_racism)\n",
    "train_loader_racism = DataLoader(train_dataset_racism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_racism = DataLoader(val_dataset_racism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_sexism = MYDataset(tokenized_train_sexism, train_labels_sexism)\n",
    "val_dataset_sexism = MYDataset(tokenized_val_sexism, val_labels_sexism)\n",
    "train_loader_sexism = DataLoader(train_dataset_sexism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_sexism = DataLoader(val_dataset_sexism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_ageism = MYDataset(tokenized_train_ageism, train_labels_ageism)\n",
    "val_dataset_ageism = MYDataset(tokenized_val_ageism, val_labels_ageism)\n",
    "train_loader_ageism = DataLoader(train_dataset_ageism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_ageism = DataLoader(val_dataset_ageism, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_benefits = MYDataset(tokenized_train_benefits, train_labels_benefits)\n",
    "val_dataset_benefits = MYDataset(tokenized_val_benefits, val_labels_benefits)\n",
    "train_loader_benefits = DataLoader(train_dataset_benefits, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_benefits = DataLoader(val_dataset_benefits, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_opportunities = MYDataset(tokenized_train_opportunities, train_labels_opportunities)\n",
    "val_dataset_opportunities = MYDataset(tokenized_val_opportunities, val_labels_opportunities)\n",
    "train_loader_opportunities = DataLoader(train_dataset_opportunities, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_opportunities = DataLoader(val_dataset_opportunities, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_privacy = MYDataset(tokenized_train_privacy, train_labels_privacy)\n",
    "val_dataset_privacy = MYDataset(tokenized_val_privacy, val_labels_privacy)\n",
    "train_loader_privacy = DataLoader(train_dataset_privacy, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_privacy = DataLoader(val_dataset_privacy, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "\n",
    "train_dataset_resources = MYDataset(tokenized_train_resources, train_labels_resources)\n",
    "val_dataset_resources = MYDataset(tokenized_val_resources, val_labels_resources)\n",
    "train_loader_resources = DataLoader(train_dataset_resources, batch_size = TRAIN_BATCH_SIZE, shuffle = False)\n",
    "val_loader_resources = DataLoader(val_dataset_resources, batch_size = TRAIN_BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all of the data into a dictionary to be able to access it all\n",
    "train_datasets = {\n",
    "    'insurance': train_dataset_insurance,\n",
    "    'safety': train_dataset_safety,\n",
    "    'balance': train_dataset_balance,\n",
    "    'retirement': train_dataset_retirement,\n",
    "    'culture': train_dataset_culture,\n",
    "    'racism': train_dataset_racism,\n",
    "    'sexism': train_dataset_sexism,\n",
    "    'ageism': train_dataset_ageism,\n",
    "    'benefits': train_dataset_benefits,\n",
    "    'opportunities': train_dataset_opportunities,\n",
    "    'privacy': train_dataset_privacy,\n",
    "    'resources': train_dataset_resources\n",
    "}\n",
    "\n",
    "train_loaders = {\n",
    "    'insurance': train_loader_insurance,\n",
    "    'safety': train_loader_safety,\n",
    "    'balance': train_loader_balance,\n",
    "    'retirement': train_loader_retirement,\n",
    "    'culture': train_loader_culture,\n",
    "    'racism': train_loader_racism,\n",
    "    'sexism': train_loader_sexism,\n",
    "    'ageism': train_loader_ageism,\n",
    "    'benefits': train_loader_benefits,\n",
    "    'opportunities': train_loader_opportunities,\n",
    "    'privacy': train_loader_privacy,\n",
    "    'resources': train_loader_resources\n",
    "}\n",
    "\n",
    "val_datasets = {\n",
    "    'insurance': val_dataset_insurance,\n",
    "    'safety': val_dataset_safety,\n",
    "    'balance': val_dataset_balance,\n",
    "    'retirement': val_dataset_retirement,\n",
    "    'culture': val_dataset_culture,\n",
    "    'racism': val_dataset_racism,\n",
    "    'sexism': val_dataset_sexism,\n",
    "    'ageism': val_dataset_ageism,\n",
    "    'benefits': val_dataset_benefits,\n",
    "    'opportunities': val_dataset_opportunities,\n",
    "    'privacy': val_dataset_privacy,\n",
    "    'resources': val_dataset_resources\n",
    "}\n",
    "\n",
    "val_loaders = {\n",
    "    'insurance': val_loader_insurance,\n",
    "    'safety': val_loader_safety,\n",
    "    'balance': val_loader_balance,\n",
    "    'retirement': val_loader_retirement,\n",
    "    'culture': val_loader_culture,\n",
    "    'racism': val_loader_racism,\n",
    "    'sexism': val_loader_sexism,\n",
    "    'ageism': val_loader_ageism,\n",
    "    'benefits': val_loader_benefits,\n",
    "    'opportunities': val_loader_opportunities,\n",
    "    'privacy': val_loader_privacy,\n",
    "    'resources': val_loader_resources\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3 - DEFINE PRETRAINED MODEL AND EVALUATE PERFORMANCE\n",
    "# activate GPU runtime by calling cuda/cpu\n",
    "device = torch.device(available_torch_device)                         # https://pytorch.org/docs/stable/generated/torch.cuda.device.html?highlight=torch%20device#torch.cuda.device\n",
    "\n",
    "# Find the DistilBert model for sequence classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\") \n",
    "\n",
    "# Assign model to the GPU device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(loader):\n",
    "    \"\"\" Calculates the true label and predicted label of a dataset's points.\n",
    "    \n",
    "    Args:\n",
    "        loader::[DataLoader]\n",
    "            A dataset's points.\n",
    "            \n",
    "    Return:\n",
    "        y_true::[np.array]\n",
    "            The true labels of the dataset's points.\n",
    "        y_predict::[np.array]\n",
    "            The predicted labels of the dataset's points.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = []\n",
    "    y_predict = []\n",
    "    count = 1\n",
    "\n",
    "    for batch in loader:\n",
    "        # In batch dictionary, there are a keys for input_ids, attention_mask and labels\n",
    "        # These three inputs are necessary for DistilBertForSequenceClassification model\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "        \n",
    "        # outputs[0] or outputs.loss is the loss and outputs[1] or outputs.logit is the logit\n",
    "        # use torch.argmax to give the one-hot encoding predictions of logits.\n",
    "        # https://huggingface.co/transformers/main_classes/output.html\n",
    "        predictions = torch.argmax(outputs.logits, dim = 1)\n",
    "        \n",
    "        # To call the numpy, you must move the gpu tensors to cpu\n",
    "        y_true_batch = labels.cpu().detach().numpy() \n",
    "        y_predict_batch = predictions.cpu().detach().numpy()\n",
    "        for i in y_true_batch:\n",
    "            y_true.append(i)\n",
    "        for j in y_predict_batch:\n",
    "            y_predict.append(j)\n",
    "            \n",
    "        # Delete the tensors with gradients to save GPU memory\n",
    "        del input_ids\n",
    "        del attention_mask\n",
    "        del labels\n",
    "        del outputs\n",
    "        del predictions\n",
    "\n",
    "        print(f'Batch {count} for current loader completed.')\n",
    "        count += 1\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_predict = np.array(y_predict)\n",
    "\n",
    "    return y_true, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_evaluate(topic, y_true, y_predict):\n",
    "    \"\"\" Makes a classification report and prints a confusion matrix..\n",
    "    \n",
    "    Args:\n",
    "        topic::[str]\n",
    "            The topic of the dataset being analyzed.\n",
    "        y_true::[np.array]\n",
    "            The true labels of the dataset's points.\n",
    "        y_predict::[np.array]\n",
    "            The predicted labels of the dataset's points.\n",
    "    \"\"\"\n",
    "    \n",
    "    target_names = [f'non-{topic}', topic]\n",
    "    \n",
    "    # Use the classification_report module to generate classification report\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "    print(classification_report(y_true, y_predict, target_names = target_names))\n",
    "    \n",
    "    # Use the confusion_matrix module to generate confusion matrix\n",
    "    # Use ConfusionMatrixDisplay to display confusion matrix with lable classes\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = target_names)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_trained_model(topic, train_datasets, val_datasets, train_loaders, val_loaders):\n",
    "    \"\"\" Trains a model on a dataset, based on a sub-topic within it.\n",
    "    \n",
    "    Args:\n",
    "        topic::[str]\n",
    "            The sub-topic of the dataset being analyzed.\n",
    "        train_datasets::[MYDataset]\n",
    "            The training dataset's features and labels.\n",
    "        val_datasets::[MYDataset]\n",
    "            The testing dataset's features and labels.\n",
    "        train_loaders::[DataLoader]\n",
    "            The training dataset in the form of an iterable.\n",
    "        val_loaders::[DataLoader]\n",
    "            The testing dataset in the form of an iterable.\n",
    "            \n",
    "    Return:\n",
    "        trainer::[Trainer]\n",
    "            The trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_len = len(Xtrains[topic])\n",
    "    test_len = len(Xvals[topic])\n",
    "    print(f'The current metric is {topic}, the training size is {train_len}, and the test size is {test_len}.')\n",
    "    print(\"Beginning model training...\")\n",
    "    \n",
    "    # get the true label and predicted label for testing and training set respectively\n",
    "    global y_true_val, y_predict_val, y_true_train, y_predict_train\n",
    "    print(\"\\nFinding values for testing set:\")\n",
    "    y_true_val, y_predict_val = predict_dataset(val_loaders[topic])\n",
    "    print(\"\\nFinding values for training set:\")\n",
    "    y_true_train, y_predict_train = predict_dataset(train_loaders[topic])\n",
    "    \n",
    "    print(\"\\nAnalyzing current model...\\n\")\n",
    "    \n",
    "    # performance evaluation for training set with pre-trained naive model\n",
    "    print(\"Classification Report on Training Set\")\n",
    "    classification_evaluate(topic, y_true_train, y_predict_train)\n",
    "    \n",
    "    # performance evaluation for testing set with pre-trained naive model\n",
    "    print(\"Classification Report on Testing Set\")\n",
    "    classification_evaluate(topic, y_true_val, y_predict_val)\n",
    "    \n",
    "    # STEP 4 - TRAIN AND EVALUATE THE MODEL\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = './results',                        # output directory\n",
    "        num_train_epochs = 3,                            # total number of training epochs\n",
    "        per_device_train_batch_size = TRAIN_BATCH_SIZE,  # batch size per device during training\n",
    "        per_device_eval_batch_size = EVAL_BATCH_SIZE,    # batch size for evaluation\n",
    "        warmup_steps = 500,                              # number of warmup steps for learning rate scheduler\n",
    "        weight_decay = 0.01,                             # strength of weight decay\n",
    "        logging_dir = './logs',                          # directory for storing logs\n",
    "        logging_steps = 50,                              # record the logs every 10 steps\n",
    "        do_eval = True,                                  # include in the validation set performance evaluation\n",
    "        evaluation_strategy = \"steps\"                    # Loss are calculated along as training step increases\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBeginning training...\\n\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = model,                                   # the instantiated 🤗 Transformers model to be trained\n",
    "        args = training_args,                            # training arguments, defined above\n",
    "        train_dataset = train_datasets[topic],           # training dataset\n",
    "        eval_dataset = val_datasets[topic]               # evaluation dataset\n",
    "    )\n",
    "\n",
    "    # execute the training\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Classifier to Measure Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_title</th>\n",
       "      <th>employee_status</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>R&amp;D Manager</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>Chemical Technician</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Company        date       employee_title  \\\n",
       "0           0  ExxonMobil  2021-05-18           IT Analyst   \n",
       "1           1  ExxonMobil  2021-09-04          R&D Manager   \n",
       "2           2  ExxonMobil  2021-10-16  Chemical Technician   \n",
       "3           3  ExxonMobil  2021-10-15            Anonymous   \n",
       "4           4  ExxonMobil  2021-10-13             Engineer   \n",
       "\n",
       "                        employee_status                review_title  \\\n",
       "0    Current Employee, more than 1 year       Great Company Overall   \n",
       "1                       Former Employee       working on energy R&D   \n",
       "2   Current Employee, more than 3 years                 Flexibility   \n",
       "3  Current Employee, more than 10 years      I can only be thankful   \n",
       "4                       Former Employee  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \n",
       "0  I have not experienced anything negative so fa...  \n",
       "1  Difficult industry business environment curren...  \n",
       "2  No downside. PERIOD. Such a great place to joi...  \n",
       "3  It is hard times right now. But for me, it's w...  \n",
       "4  Even if you worked your tail off the whole yea...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open review dataset\n",
    "prelim_reviews = pd.read_csv(\"all_reviews.csv\", header = 0, sep = \";\")\n",
    "prelim_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_title</th>\n",
       "      <th>employee_status</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>R&amp;D Manager</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>Chemical Technician</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company        date       employee_title  \\\n",
       "0  ExxonMobil  2021-05-18           IT Analyst   \n",
       "1  ExxonMobil  2021-09-04          R&D Manager   \n",
       "2  ExxonMobil  2021-10-16  Chemical Technician   \n",
       "3  ExxonMobil  2021-10-15            Anonymous   \n",
       "4  ExxonMobil  2021-10-13             Engineer   \n",
       "\n",
       "                        employee_status                review_title  \\\n",
       "0    Current Employee, more than 1 year       Great Company Overall   \n",
       "1                       Former Employee       working on energy R&D   \n",
       "2   Current Employee, more than 3 years                 Flexibility   \n",
       "3  Current Employee, more than 10 years      I can only be thankful   \n",
       "4                       Former Employee  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \n",
       "0  I have not experienced anything negative so fa...  \n",
       "1  Difficult industry business environment curren...  \n",
       "2  No downside. PERIOD. Such a great place to joi...  \n",
       "3  It is hard times right now. But for me, it's w...  \n",
       "4  Even if you worked your tail off the whole yea...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop weird column\n",
    "reviews = prelim_reviews.drop([\"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                review_title  \\\n",
       "0  ExxonMobil       Great Company Overall   \n",
       "1  ExxonMobil       working on energy R&D   \n",
       "2  ExxonMobil                 Flexibility   \n",
       "3  ExxonMobil      I can only be thankful   \n",
       "4  ExxonMobil  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0  I have not experienced anything negative so fa...   \n",
       "1  Difficult industry business environment curren...   \n",
       "2  No downside. PERIOD. Such a great place to joi...   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.87   \n",
       "1  pro outstanding colleague working high impact ...       0.32       0.65   \n",
       "2  pro flexibility nature working like family env...       0.86       0.93   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.91   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       0.72   \n",
       "\n",
       "  score_combined  \n",
       "0           0.97  \n",
       "1           0.77  \n",
       "2           0.96  \n",
       "3           0.93  \n",
       "4            0.9  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean reviews\n",
    "reviews = glass_door_review_cleaner(reviews)\n",
    "reviews[\"text\"] = final_review_cleaner(reviews)\n",
    "\n",
    "# remove NaN/invalid values\n",
    "# reviews = reviews.dropna()\n",
    "\n",
    "# add sentiment analyses\n",
    "pros_sentiment = retrieve_sentiment_analysis(reviews, \"pros\")\n",
    "cons_sentiment = retrieve_sentiment_analysis(reviews, \"cons\")\n",
    "combined_sentiment = retrieve_sentiment_analysis(reviews, \"text\")\n",
    "\n",
    "reviews[\"score_pros\"] = pros_sentiment[\"compound\"]\n",
    "reviews[\"score_cons\"] = cons_sentiment[\"compound\"]\n",
    "reviews[\"score_combined\"] = combined_sentiment[\"compound\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9290, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current metric is resources, the training size is 1603, and the test size is 401.\n",
      "Beginning model training...\n",
      "Batch 1 for current loader completed.\n",
      "Batch 2 for current loader completed.\n",
      "Batch 3 for current loader completed.\n",
      "Batch 4 for current loader completed.\n",
      "Batch 5 for current loader completed.\n",
      "Batch 6 for current loader completed.\n",
      "Batch 7 for current loader completed.\n",
      "Batch 8 for current loader completed.\n",
      "Batch 9 for current loader completed.\n",
      "Batch 10 for current loader completed.\n",
      "Batch 11 for current loader completed.\n",
      "Batch 12 for current loader completed.\n",
      "Batch 13 for current loader completed.\n",
      "Batch 14 for current loader completed.\n",
      "Batch 15 for current loader completed.\n",
      "Batch 16 for current loader completed.\n",
      "Batch 17 for current loader completed.\n",
      "Batch 18 for current loader completed.\n",
      "Batch 19 for current loader completed.\n",
      "Batch 20 for current loader completed.\n",
      "Batch 21 for current loader completed.\n",
      "Batch 22 for current loader completed.\n",
      "Batch 23 for current loader completed.\n",
      "Batch 24 for current loader completed.\n",
      "Batch 25 for current loader completed.\n",
      "Batch 26 for current loader completed.\n",
      "Batch 27 for current loader completed.\n",
      "Batch 28 for current loader completed.\n",
      "Batch 29 for current loader completed.\n",
      "Batch 30 for current loader completed.\n",
      "Batch 31 for current loader completed.\n",
      "Batch 32 for current loader completed.\n",
      "Batch 33 for current loader completed.\n",
      "Batch 34 for current loader completed.\n",
      "Batch 35 for current loader completed.\n",
      "Batch 36 for current loader completed.\n",
      "Batch 37 for current loader completed.\n",
      "Batch 38 for current loader completed.\n",
      "Batch 39 for current loader completed.\n",
      "Batch 40 for current loader completed.\n",
      "Batch 41 for current loader completed.\n",
      "Batch 1 for current loader completed.\n",
      "Batch 2 for current loader completed.\n",
      "Batch 3 for current loader completed.\n",
      "Batch 4 for current loader completed.\n",
      "Batch 5 for current loader completed.\n",
      "Batch 6 for current loader completed.\n",
      "Batch 7 for current loader completed.\n",
      "Batch 8 for current loader completed.\n",
      "Batch 9 for current loader completed.\n",
      "Batch 10 for current loader completed.\n",
      "Batch 11 for current loader completed.\n",
      "True and predicted values found...\n",
      "\n",
      "Classification Report on Training Set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-resources       0.96      1.00      0.98       384\n",
      "    resources       0.00      0.00      0.00        17\n",
      "\n",
      "     accuracy                           0.96       401\n",
      "    macro avg       0.48      0.50      0.49       401\n",
      " weighted avg       0.92      0.96      0.94       401\n",
      "\n",
      "Confusion Matrix:\n",
      "[[384   0]\n",
      " [ 17   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Bella\\anaconda3\\envs\\data-x\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "using `logging_steps` to initialize `eval_steps` to 50\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Testing Set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-resources       0.95      1.00      0.98      1525\n",
      "    resources       0.00      0.00      0.00        78\n",
      "\n",
      "     accuracy                           0.95      1603\n",
      "    macro avg       0.48      0.50      0.49      1603\n",
      " weighted avg       0.91      0.95      0.93      1603\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1525    0]\n",
      " [  78    0]]\n",
      "Training arguments completed...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1603\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 40\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 40\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 2:33:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.179748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.185466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 401\n",
      "  Batch size = 60\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 401\n",
      "  Batch size = 60\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = retrieve_trained_model(CURRENT_METRIC, train_datasets, val_datasets, val_loaders, train_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters in pytorch\n",
    "torch.save(model.state_dict(), f'pytorchversion_{CURRENT_METRIC}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Pays well Schedule Nice bonus Safety oriented Cares about people. \n",
      "Label: 0\n",
      "\n",
      "Text: Good benefits and good ways for career progression. \n",
      "Label: 0\n",
      "\n",
      "Text: Great people and tons of opportunities. \n",
      "Label: 0\n",
      "\n",
      "Text: Good pay and benefits. Good work life balance.. \n",
      "Label: 0\n",
      "\n",
      "Text: The package\n",
      "Label: 0\n",
      "\n",
      "Text: Great team culture. Good compensation. Values work life balance. Flexible schedules. Good benefits.. \n",
      "Label: 0\n",
      "\n",
      "Text: Benefits\n",
      "Label: 0\n",
      "\n",
      "Text: High salary\n",
      "Label: 0\n",
      "\n",
      "Text: Strong management\n",
      "Label: 0\n",
      "\n",
      "Text: Dependable job. Insurance was great until Obama ruined it. Great officers - team players.. \n",
      "Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspecting misclassified samples in the validation to guide next improvement steps\n",
    "for i in range(10):\n",
    "    text = Xvals[CURRENT_METRIC][y_true_val != y_predict_val].iloc[i]['text']\n",
    "    label = '?'\n",
    "    label = Xvals[CURRENT_METRIC][y_true_val != y_predict_val].iloc[i][CURRENT_METRIC]\n",
    "    print(f'Text: {text}\\nLabel: {label}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Classifier\n",
    "*This section only focuses on the text column. For focus on pros and cons individually, see \"Automating the Classifier\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric List: ['insurance', 'safety', 'balance', 'retirement', 'culture', 'racism', 'sexism', 'ageism', 'benefits', 'opportunities', 'privacy', 'resources']\n",
      "Which of the 12 metrics would you like to focus on currently?: retirement\n",
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                review_title  \\\n",
       "0  ExxonMobil       Great Company Overall   \n",
       "1  ExxonMobil       working on energy R&D   \n",
       "2  ExxonMobil                 Flexibility   \n",
       "3  ExxonMobil      I can only be thankful   \n",
       "4  ExxonMobil  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0  I have not experienced anything negative so fa...   \n",
       "1  Difficult industry business environment curren...   \n",
       "2  No downside. PERIOD. Such a great place to joi...   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.87   \n",
       "1  pro outstanding colleague working high impact ...       0.32       0.65   \n",
       "2  pro flexibility nature working like family env...       0.86       0.93   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.91   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       0.72   \n",
       "\n",
       "  score_combined  \n",
       "0           0.97  \n",
       "1           0.77  \n",
       "2           0.96  \n",
       "3           0.93  \n",
       "4            0.9  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 - FORMAL DEPLOYMENT\n",
    "# Note: If this is an existing session, do NOT run this cell\n",
    "#       If this is a new session, please re-run Step 1 and this cell\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = torch.device(available_torch_device)\n",
    "\n",
    "print(f'Metric List: {metrics}')\n",
    "CURRENT_METRIC = input(f'Which of the {len(metrics)} metrics would you like to focus on currently?: ')\n",
    "\n",
    "# load the saved weights to the pretrained the model\n",
    "model.load_state_dict(torch.load(f'pytorchversion_{CURRENT_METRIC}.pkl', map_location = available_torch_device))\n",
    "model.to(device)\n",
    "\n",
    "# reload and clean the review dataset\n",
    "prelim_reviews = pd.read_csv(\"all_reviews.csv\", header = 0, sep = \";\")\n",
    "reviews = prelim_reviews.drop([\"Unnamed: 0\"], axis = 1)\n",
    "reviews = glass_door_review_cleaner(reviews)\n",
    "reviews[\"text\"] = final_review_cleaner(reviews)\n",
    "\n",
    "# remove NaN/invalid values\n",
    "# reviews = reviews.dropna()\n",
    "\n",
    "# add sentiment analyses\n",
    "pros_sentiment = retrieve_sentiment_analysis(reviews, \"pros\")\n",
    "cons_sentiment = retrieve_sentiment_analysis(reviews, \"cons\")\n",
    "combined_sentiment = retrieve_sentiment_analysis(reviews, \"text\")\n",
    "\n",
    "reviews[\"score_pros\"] = pros_sentiment[\"compound\"]\n",
    "reviews[\"score_cons\"] = cons_sentiment[\"compound\"]\n",
    "reviews[\"score_combined\"] = combined_sentiment[\"compound\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at C:\\Users\\Bella/.cache\\huggingface\\transformers\\ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "# test case\n",
    "# input_args = [\"i love insurance\", \"resources\", \"i hate their insurance\"]\n",
    "# tokenized_dep = tokenizer(input_args, padding = \"max_length\", truncation = True)\n",
    "# dep_labels = [0] * len(input_args)\n",
    "\n",
    "# tokenize input_arguments \n",
    "tokenized_dep = tokenizer(reviews[\"text\"].astype(str).values.tolist(), padding = \"max_length\", truncation = True)\n",
    "\n",
    "# assumed dep_labels, with the same length of input arguments, if you don't know the exact labels just set them to zeros as example\n",
    "dep_labels = [0] * len(reviews[\"text\"].astype(str).values.tolist())\n",
    "\n",
    "# make dep_dataset with input arguments and assumed dep_labels\n",
    "dep_dataset = MYDataset(tokenized_dep, dep_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    }
   ],
   "source": [
    "# get the y_predict of input tokens, similar to the function \"predict_dataset\" shown in STEP3\n",
    "dep_loader = DataLoader(dep_dataset, batch_size = 1, shuffle = False)\n",
    "y_predict = []\n",
    "count = 1\n",
    "\n",
    "for batch in dep_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "    \n",
    "    predictions = torch.argmax(outputs.logits, dim = 1)\n",
    "    y_predict_batch = predictions.cpu().detach().numpy()\n",
    "    for j in y_predict_batch:\n",
    "        y_predict.append(j)\n",
    "        \n",
    "    del input_ids\n",
    "    del attention_mask\n",
    "    del labels\n",
    "    del outputs\n",
    "    del predictions\n",
    "    \n",
    "    if count % 250 == 0:\n",
    "        print(f'Batch {count} for review loader completed.')\n",
    "    count += 1\n",
    "\n",
    "y_predict = np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pro pension health insurance benefit rotating ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pro benefit salary people environment campus c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pro overall good place work con reorganization...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pro people assignment opportunity benefit sala...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pro great place work depending career path gro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pro awesome company work con nothing really co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pro work best brightest challenging fun assign...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pro salary nice campus con toxic culture emplo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pro great environment work culture good collea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pro base salary good plenty time studying self...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pro stability consistency fun past hope verge ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pro excellent training prior smart colleague e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pro great place work good benefit con large co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pro learn lot short period time meet good peop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pro compensation benefit package workplace fle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pro great benefit pay great parental time cons...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pro lot people work delightful willing teach g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pro work quality people lot opportunity job lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pro get work smart people learn great deal ben...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pro huge resource meritocracy intriguin intell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pro career development process based internal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pro benefit best thing company con upper manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pro paid well competitive environment new oppo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pro good work gas always pump con need better ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pro solid pay need much con play lot telephone...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  prediction\n",
       "0   pro great work environment great benefit prett...           0\n",
       "1   pro outstanding colleague working high impact ...           0\n",
       "2   pro flexibility nature working like family env...           0\n",
       "3   pro achieving dream partnership company thankf...           0\n",
       "4   pro competitive pay structured benefit job sat...           0\n",
       "5   pro pension health insurance benefit rotating ...           0\n",
       "6   pro benefit salary people environment campus c...           0\n",
       "7   pro overall good place work con reorganization...           0\n",
       "8   pro people assignment opportunity benefit sala...           0\n",
       "9   pro great place work depending career path gro...           0\n",
       "10  pro awesome company work con nothing really co...           0\n",
       "11  pro work best brightest challenging fun assign...           0\n",
       "12  pro salary nice campus con toxic culture emplo...           0\n",
       "13  pro great environment work culture good collea...           0\n",
       "14  pro base salary good plenty time studying self...           0\n",
       "15  pro stability consistency fun past hope verge ...           0\n",
       "16  pro excellent training prior smart colleague e...           0\n",
       "17  pro great place work good benefit con large co...           0\n",
       "18  pro learn lot short period time meet good peop...           0\n",
       "19  pro compensation benefit package workplace fle...           0\n",
       "20  pro great benefit pay great parental time cons...           0\n",
       "21  pro lot people work delightful willing teach g...           0\n",
       "22  pro work quality people lot opportunity job lo...           0\n",
       "23  pro get work smart people learn great deal ben...           0\n",
       "24  pro huge resource meritocracy intriguin intell...           0\n",
       "25  pro career development process based internal ...           0\n",
       "26  pro benefit best thing company con upper manag...           0\n",
       "27  pro paid well competitive environment new oppo...           0\n",
       "28  pro good work gas always pump con need better ...           0\n",
       "29  pro solid pay need much con play lot telephone...           0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "# deployment_dict = {\n",
    "#     'text': input_args,\n",
    "#     'prediction': y_predict\n",
    "# }\n",
    "\n",
    "deployment_dict = {\n",
    "    'text': reviews[\"text\"],\n",
    "    'prediction': y_predict\n",
    "}\n",
    "\n",
    "deployment_output = pd.DataFrame(deployment_dict)\n",
    "deployment_output.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "      <th>retirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so fa...</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to joi...</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                review_title  \\\n",
       "0  ExxonMobil       Great Company Overall   \n",
       "1  ExxonMobil       working on energy R&D   \n",
       "2  ExxonMobil                 Flexibility   \n",
       "3  ExxonMobil      I can only be thankful   \n",
       "4  ExxonMobil  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0  I have not experienced anything negative so fa...   \n",
       "1  Difficult industry business environment curren...   \n",
       "2  No downside. PERIOD. Such a great place to joi...   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.87   \n",
       "1  pro outstanding colleague working high impact ...       0.32       0.65   \n",
       "2  pro flexibility nature working like family env...       0.86       0.93   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.91   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       0.72   \n",
       "\n",
       "  score_combined  retirement  \n",
       "0           0.97           0  \n",
       "1           0.77           0  \n",
       "2           0.96           0  \n",
       "3           0.93           0  \n",
       "4            0.9           0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[CURRENT_METRIC] = y_predict\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of original reviews: {reviews.shape}')\n",
    "print(f'Shape of reviews predicted with metric: {reviews[reviews[CURRENT_METRIC] == 1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(f'classified_{CURRENT_METRIC}.csv', sep = ';', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating the Classifier (optional)\n",
    "*This section focuses on classifying all metrics on the pros and cons columns individually.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_title</th>\n",
       "      <th>employee_status</th>\n",
       "      <th>review_title</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>text</th>\n",
       "      <th>score_pros</th>\n",
       "      <th>score_cons</th>\n",
       "      <th>score_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>IT Analyst</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>Great Company Overall</td>\n",
       "      <td>Great work environment Great benefits Pretty g...</td>\n",
       "      <td>I have not experienced anything negative so far</td>\n",
       "      <td>pro great work environment great benefit prett...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>R&amp;D Manager</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>working on energy R&amp;D</td>\n",
       "      <td>Outstanding colleagues, working on high impact...</td>\n",
       "      <td>Difficult industry business environment curren...</td>\n",
       "      <td>pro outstanding colleague working high impact ...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>Chemical Technician</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Flexibility</td>\n",
       "      <td>The flexibility and the nature of working ther...</td>\n",
       "      <td>No downside. PERIOD. Such a great place to join.</td>\n",
       "      <td>pro flexibility nature working like family env...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>I can only be thankful</td>\n",
       "      <td>I am achieving my dreams in partnership with t...</td>\n",
       "      <td>It is hard times right now. But for me, it's w...</td>\n",
       "      <td>pro achieving dream partnership company thankf...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>2021-10-13</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Decent company to work for</td>\n",
       "      <td>Competitive pay, structured benefits, and job ...</td>\n",
       "      <td>Even if you worked your tail off the whole yea...</td>\n",
       "      <td>pro competitive pay structured benefit job sat...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company        date       employee_title  \\\n",
       "0  ExxonMobil  2021-05-18           IT Analyst   \n",
       "1  ExxonMobil  2021-09-04          R&D Manager   \n",
       "2  ExxonMobil  2021-10-16  Chemical Technician   \n",
       "3  ExxonMobil  2021-10-15            Anonymous   \n",
       "4  ExxonMobil  2021-10-13             Engineer   \n",
       "\n",
       "                        employee_status                review_title  \\\n",
       "0    Current Employee, more than 1 year       Great Company Overall   \n",
       "1                       Former Employee       working on energy R&D   \n",
       "2   Current Employee, more than 3 years                 Flexibility   \n",
       "3  Current Employee, more than 10 years      I can only be thankful   \n",
       "4                       Former Employee  Decent company to work for   \n",
       "\n",
       "                                                pros  \\\n",
       "0  Great work environment Great benefits Pretty g...   \n",
       "1  Outstanding colleagues, working on high impact...   \n",
       "2  The flexibility and the nature of working ther...   \n",
       "3  I am achieving my dreams in partnership with t...   \n",
       "4  Competitive pay, structured benefits, and job ...   \n",
       "\n",
       "                                                cons  \\\n",
       "0    I have not experienced anything negative so far   \n",
       "1  Difficult industry business environment curren...   \n",
       "2   No downside. PERIOD. Such a great place to join.   \n",
       "3  It is hard times right now. But for me, it's w...   \n",
       "4  Even if you worked your tail off the whole yea...   \n",
       "\n",
       "                                                text score_pros score_cons  \\\n",
       "0  pro great work environment great benefit prett...       0.95       0.46   \n",
       "1  pro outstanding colleague working high impact ...       0.32      -0.36   \n",
       "2  pro flexibility nature working like family env...       0.86       0.79   \n",
       "3  pro achieving dream partnership company thankf...       0.77       0.28   \n",
       "4  pro competitive pay structured benefit job sat...        0.7       -0.2   \n",
       "\n",
       "  score_combined  \n",
       "0           0.96  \n",
       "1          -0.05  \n",
       "2           0.95  \n",
       "3           0.81  \n",
       "4           0.61  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload and clean the review dataset\n",
    "prelim_reviews = pd.read_csv(\"all_reviews.csv\", header = 0, sep = \";\")\n",
    "reviews = prelim_reviews.drop([\"Unnamed: 0\"], axis = 1)\n",
    "reviews = glass_door_review_cleaner(reviews)\n",
    "reviews[\"text\"] = final_review_cleaner(reviews)\n",
    "\n",
    "# remove NaN/invalid values\n",
    "# reviews = reviews.dropna()\n",
    "\n",
    "# add sentiment analyses\n",
    "pros_sentiment = retrieve_sentiment_analysis(reviews, \"pros\")\n",
    "cons_sentiment = retrieve_sentiment_analysis(reviews, \"cons\")\n",
    "combined_sentiment = retrieve_sentiment_analysis(reviews, \"text\")\n",
    "\n",
    "reviews[\"score_pros\"] = pros_sentiment[\"compound\"]\n",
    "reviews[\"score_cons\"] = cons_sentiment[\"compound\"]\n",
    "reviews[\"score_combined\"] = combined_sentiment[\"compound\"]\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_BERT(reviews_df, column, metric)\n",
    "    \"\"\" Classifies the metrics for a given dataset into their own columns.\n",
    "    \n",
    "    Args:\n",
    "        reviews_df::[pd.DataFrame]\n",
    "            The reviews table to analyze.\n",
    "        column::[str]\n",
    "            The column of values within the table to be classified.\n",
    "        metric::[str]\n",
    "            The specific metric to base the classification on.\n",
    "    \"\"\"\n",
    "\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "    device = torch.device(available_torch_device)\n",
    "    \n",
    "    # load the saved weights to the pretrained the model\n",
    "    model.load_state_dict(torch.load(f'pytorchversion_{metric}.pkl', map_location = available_torch_device))\n",
    "    model.to(device)\n",
    "    \n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "    # tokenize input_arguments \n",
    "    tokenized_dep = tokenizer(reviews_df[column].astype(str).values.tolist(), padding = \"max_length\", truncation = True)\n",
    "\n",
    "    # assumed dep_labels, with the same length of input arguments, if you don't know the exact labels just set them to zeros as example\n",
    "    dep_labels = [0] * len(reviews_df[column].astype(str).values.tolist())\n",
    "\n",
    "    # make dep_dataset with input arguments and assumed dep_labels\n",
    "    dep_dataset = MYDataset(tokenized_dep, dep_labels)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    dep_loader = DataLoader(dep_dataset, batch_size = 1, shuffle = False)\n",
    "    y_predict = []\n",
    "    count = 1\n",
    "\n",
    "    for batch in dep_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim = 1)\n",
    "        y_predict_batch = predictions.cpu().detach().numpy()\n",
    "        for j in y_predict_batch:\n",
    "            y_predict.append(j)\n",
    "\n",
    "        del input_ids\n",
    "        del attention_mask\n",
    "        del labels\n",
    "        del outputs\n",
    "        del predictions\n",
    "\n",
    "        if count % 250 == 0:\n",
    "            print(f'Batch {count} for review loader completed.')\n",
    "        count += 1\n",
    "\n",
    "    y_predict = np.array(y_predict)\n",
    "    \n",
    "    deployment_dict = {\n",
    "        'text': reviews_df[\"text\"],\n",
    "        'prediction': y_predict\n",
    "    }\n",
    "\n",
    "    deployment_output = pd.DataFrame(deployment_dict)\n",
    "    \n",
    "    reviews_df[f'{metric}_{column}'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250 for review loader completed.\n",
      "Batch 500 for review loader completed.\n",
      "Batch 750 for review loader completed.\n",
      "Batch 1000 for review loader completed.\n",
      "Batch 1250 for review loader completed.\n",
      "Batch 1500 for review loader completed.\n",
      "Batch 1750 for review loader completed.\n",
      "Batch 2000 for review loader completed.\n",
      "Batch 2250 for review loader completed.\n",
      "Batch 2500 for review loader completed.\n",
      "Batch 2750 for review loader completed.\n",
      "Batch 3000 for review loader completed.\n",
      "Batch 3250 for review loader completed.\n",
      "Batch 3500 for review loader completed.\n",
      "Batch 3750 for review loader completed.\n",
      "Batch 4000 for review loader completed.\n",
      "Batch 4250 for review loader completed.\n",
      "Batch 4500 for review loader completed.\n",
      "Batch 4750 for review loader completed.\n",
      "Batch 5000 for review loader completed.\n",
      "Batch 5250 for review loader completed.\n",
      "Batch 5500 for review loader completed.\n",
      "Batch 5750 for review loader completed.\n",
      "Batch 6000 for review loader completed.\n",
      "Batch 6250 for review loader completed.\n",
      "Batch 6500 for review loader completed.\n",
      "Batch 6750 for review loader completed.\n",
      "Batch 7000 for review loader completed.\n",
      "Batch 7250 for review loader completed.\n",
      "Batch 7500 for review loader completed.\n",
      "Batch 7750 for review loader completed.\n",
      "Batch 8000 for review loader completed.\n",
      "Batch 8250 for review loader completed.\n",
      "Batch 8500 for review loader completed.\n",
      "Batch 8750 for review loader completed.\n",
      "Batch 9000 for review loader completed.\n",
      "Batch 9250 for review loader completed.\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    classify_with_BERT(reviews, 'pros', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reviews predicted with insurance_pros metric: (0, 32)\n",
      "Shape of reviews predicted with insurance_cons metric: (0, 32)\n",
      "Shape of reviews predicted with safety_pros metric: (0, 32)\n",
      "Shape of reviews predicted with safety_cons metric: (0, 32)\n",
      "Shape of reviews predicted with balance_pros metric: (562, 32)\n",
      "Shape of reviews predicted with balance_cons metric: (0, 32)\n",
      "Shape of reviews predicted with retirement_pros metric: (0, 32)\n",
      "Shape of reviews predicted with retirement_cons metric: (0, 32)\n",
      "Shape of reviews predicted with culture_pros metric: (0, 32)\n",
      "Shape of reviews predicted with culture_cons metric: (0, 32)\n",
      "Shape of reviews predicted with racism_pros metric: (0, 32)\n",
      "Shape of reviews predicted with racism_cons metric: (0, 32)\n",
      "Shape of reviews predicted with sexism_pros metric: (0, 32)\n",
      "Shape of reviews predicted with sexism_cons metric: (0, 32)\n",
      "Shape of reviews predicted with ageism_pros metric: (0, 32)\n",
      "Shape of reviews predicted with ageism_cons metric: (0, 32)\n",
      "Shape of reviews predicted with benefits_pros metric: (7, 32)\n",
      "Shape of reviews predicted with benefits_cons metric: (0, 32)\n",
      "Shape of reviews predicted with opportunities_pros metric: (0, 32)\n",
      "Shape of reviews predicted with opportunities_cons metric: (0, 32)\n",
      "Shape of reviews predicted with privacy_pros metric: (0, 32)\n",
      "Shape of reviews predicted with privacy_cons metric: (0, 32)\n",
      "Shape of reviews predicted with resources_pros metric: (0, 32)\n",
      "Shape of reviews predicted with resources_cons metric: (0, 32)\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    shape_p = reviews[reviews[f'{metric}_pros'] == 1].shape\n",
    "    shape_c = reviews[reviews[f'{metric}_cons'] == 1].shape\n",
    "    print(f'Shape of reviews predicted with {metric}_pros metric: {shape_p}')\n",
    "    print(f'Shape of reviews predicted with {metric}_cons metric: {shape_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv('all_reviews_classified_BERT.csv', sep = ';', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
